# -*- coding: utf-8 -*-
"""tflite_edge_test_v2.0

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W6iKnBDI435Lf_n-TWcYMDheIwdxJ0rG

# Image classification with TensorFlow Lite Model Maker

## Part 1: TensorFlow Evaluation

### Step 0: Prerequisites

To run this example, we first need to install several required packages, including Model Maker package that in GitHub [repo](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker).
"""

!pip install -q tensorflow==2.7.0
!pip install -q flatbuffers==1.12

import tensorflow
print(tensorflow.__version__)

!pip install -q tflite-model-maker

"""Import the required packages."""

import os
# import cv2
import numpy as np

import tensorflow as tf
from tensorflow.python.client import device_lib
assert tf.__version__.startswith('2')

from tflite_model_maker import model_spec
from tflite_model_maker import image_classifier
from tflite_model_maker.config import ExportFormat
from tflite_model_maker.config import QuantizationConfig
from tflite_model_maker.image_classifier import DataLoader

import matplotlib.pyplot as plt

from google.colab import drive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

import logging
logging.getLogger('googleapiclient.discovery_cache').setLevel(logging.ERROR)

import time
from datetime import datetime

import multiprocessing
import csv

# Constants
training_dataset_path = '/gdrive/MyDrive/Colab Notebooks/data/gaf_output/content/gaf_output/training/'
test_dataset_path = '/gdrive/MyDrive/Colab Notebooks/data/gaf_output/content/gaf_output/test/'
folder_name = 'content/gaf/gaf_output/'
test_dataset_fileid = '13vOy94hClYWFK98kzYUn8IHgC6jSxFV0'
test_dataset_filename = 'gaf_dataset_test.csv'
tflite_model_filename = 'model.tflite'
EPOCHS = 35

"""Step 1.   Load input data specific to an on-device ML app. Split it into training data and testing data."""

# Commented out IPython magic to ensure Python compatibility.
# Mount Google Drive
drive.mount('/gdrive', force_remount=True)
# %cd /gdrive/MyDrive/Colab\ Notebooks/data/gaf_output/content/gaf_output

# Create dataset from folder
data = DataLoader.from_folder(training_dataset_path)

"""Split it to training data (80%), validation data (10%, optional) and testing data (10%)."""

# Split dataset into training, validation, and testing subsets
train_data, rest_data = data.split(0.8)
validation_data, test_data = rest_data.split(0.5)
print('Data sizes:', data.size, train_data.size, rest_data.size, validation_data.size, test_data.size)

"""Show 25 image examples with labels."""

plt.figure(figsize=(20,20))
for i, (image, label) in enumerate(data.gen_dataset().unbatch().take(25)):
  plt.subplot(5,5,i+1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(image.numpy(), cmap=plt.cm.gray)
  plt.xlabel(data.index_to_label[label.numpy()])
plt.show()

"""### Step 1: Customize the TensorFlow Model

Create a custom image classifier model based on the loaded data. The default model is EfficientNet-Lite0.

"""

training_time_start = time.clock()
model = image_classifier.create(train_data, validation_data=validation_data, epochs=EPOCHS)
training_time_elapsed = (time.clock() - training_time_start)
print('training_time_elapsed:', training_time_elapsed)

"""Have a look at the detailed model structure."""

model.summary()

"""### Step 2: Evaluate the Customized Model

Evaluate the result of the model, get the loss and accuracy of the model.
"""

eval_time_start = time.clock()
loss, accuracy = model.evaluate(test_data)
eval_time_elapsed = (time.clock() - eval_time_start)
print('eval_time_elapsed:', eval_time_elapsed)

"""We could plot the predicted results in 100 test images. Predicted labels with red color are the wrong predicted results while others are correct."""

# A helper function that returns 'red'/'black' depending on if its two input
# parameter matches or not.
def get_label_color(val1, val2):
  if val1 == val2:
    return 'black'
  else:
    return 'red'

# Then plot 100 test images and their predicted labels.
# If a prediction result is different from the label provided label in "test"
# dataset, we will highlight it in red color.
plt.figure(figsize=(30, 30))
predicts = model.predict_top_k(test_data)
for i, (image, label) in enumerate(test_data.gen_dataset().unbatch().take(100)):
  ax = plt.subplot(10, 10, i+1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(image.numpy(), cmap=plt.cm.gray)

  predict_label = predicts[i][0][0]
  color = get_label_color(predict_label,
                          test_data.index_to_label[label.numpy()])
  ax.xaxis.label.set_color(color)
  plt.xlabel('Predicted: %s' % predict_label)
plt.show()

"""If the accuracy doesn't meet the app requirement, one could refer to [Advanced Usage](#scrollTo=zNDBP2qA54aK) to explore alternatives such as changing to a larger model, adjusting re-training parameters etc.

### Step 3: Export to TensorFlow Lite Model

Convert the trained model to TensorFlow Lite model format with [metadata](https://www.tensorflow.org/lite/convert/metadata) so that you can later use in an on-device ML application. The label file and the vocab file are embedded in metadata. The default TFLite filename is `model.tflite`.

In many on-device ML application, the model size is an important factor. Therefore, it is recommended that you apply quantize the model to make it smaller and potentially run faster.
The default post-training quantization technique is full integer quantization for the image classification task.
"""

model_export_time_start = time.clock()
model.export(export_dir='.', tflite_filename='epochs-' + str(EPOCHS) + '-' + tflite_model_filename)
model_export_time_elapsed = (time.clock() - model_export_time_start)
print('model_export_time_elapsed:', model_export_time_elapsed)

model.export(export_dir='.', export_format=ExportFormat.LABEL)

"""You can also evaluate the tflite model with the `evaluate_tflite` method."""

tflite_eval_time_start = time.process_time()
tflite_accuracy = model.evaluate_tflite('epochs-' + str(EPOCHS) + '-' + tflite_model_filename, test_data)
print('TFLite accuracy:', tflite_accuracy)
tflite_eval_time_elapsed = time.process_time()
tflite_eval_time_elapsed = (tflite_eval_time_elapsed - tflite_eval_time_start)
print('tflite_eval_time_elapsed:', tflite_eval_time_elapsed)

"""### Advanced Usage Tips

The `create` function is the critical part of this library. It uses transfer learning with a pretrained model similar to the [tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning).

The `create` function contains the following steps:

1.   Split the data into training, validation, testing data according to parameter `validation_ratio` and `test_ratio`. The default value of `validation_ratio` and `test_ratio` are `0.1` and `0.1`.
2.   Download a [Image Feature Vector](https://www.tensorflow.org/hub/common_signatures/images#image_feature_vector) as the base model from TensorFlow Hub. The default pre-trained model is  EfficientNet-Lite0.
3.   Add a classifier head with a Dropout Layer with `dropout_rate` between head layer and pre-trained model. The default `dropout_rate` is the default `dropout_rate` value from [make_image_classifier_lib](https://github.com/tensorflow/hub/blob/master/tensorflow_hub/tools/make_image_classifier/make_image_classifier_lib.py#L55) by TensorFlow Hub.
4.   Preprocess the raw input data. Currently, preprocessing steps including normalizing the value of each image pixel to model input scale and resizing it to model input size.   EfficientNet-Lite0 have the input scale `[0, 1]` and the input image size `[224, 224, 3]`.
5.   Feed the data into the classifier model. By default, the training parameters such as training epochs, batch size, learning rate, momentum are the default values from [make_image_classifier_lib](https://github.com/tensorflow/hub/blob/master/tensorflow_hub/tools/make_image_classifier/make_image_classifier_lib.py#L55) by TensorFlow Hub. Only the classifier head is trained.


In this section, we describe several advanced topics, including switching to a different image classification model, changing the training hyperparameters etc.

## Part 2: TFLite Evaluation
"""

files_list = []
labels = ['abnormal', 'normal'] # in correct order

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

import logging
import pandas as pd
import tensorflow as tf
import numpy as np
import cv2

# Import PyDrive and associated libraries.
# This only needs to be done once per notebook.
logging.getLogger('googleapiclient.discovery_cache').setLevel(logging.ERROR)

# Authenticate and create the PyDrive client.
# This only needs to be done once per notebook.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

_dataset = drive.CreateFile({'id': test_dataset_fileid})
edge_dataset_file = _dataset.GetContentFile(test_dataset_filename)

edge_dataset = pd.read_csv(test_dataset_filename, header=0)
files_list = edge_dataset['image_name'].values
# print(files_list)
print(edge_dataset.head())
# sample = edge_dataset.loc[edge_dataset['image_name'] == '8475769_3dea463364_m.jpg'].label_no[0]
# sample_alt = edge_dataset.loc[edge_dataset['image_name'] == '8475769_3dea463364_m.jpg']['label_no'][0]
# print(sample_alt)

tflite_model_eval2_time_start = time.clock()
interpreter = tf.lite.Interpreter(model_path='epochs-' + str(EPOCHS) + '-' + tflite_model_filename)
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
print('Display inputs and outputs:')
print(input_details)
print(output_details)

print('files_list:', len(files_list))

height = input_details[0]['shape'][1]
width = input_details[0]['shape'][2]
print('width:', width, 'height', height)
predictions = []

for file in files_list:
  image_path = test_dataset_path + file 
  print('file:', image_path)
  image = cv2.imread(image_path)
  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
  imH, imW, _ = image.shape 
  image_resized = cv2.resize(image_rgb, (width, height))
  input_data = np.expand_dims(image_resized, axis=0)

  # Perform the actual detection by running the model with the image as input
  interpreter.set_tensor(input_details[0]['index'],input_data)
  interpreter.invoke()

  prediction_tensor = interpreter.get_tensor(output_details[0]['index']) 
  prediction = not bool(np.argmax(prediction_tensor))
  prediction_label = labels[np.argmax(prediction_tensor)]
  predictions.append(prediction)
  print('TFLite tensor:', prediction_tensor, '- prediction label:', prediction_label, '- prediction:', prediction)
tflite_model_eval2_time_elapsed = time.clock() - tflite_model_eval2_time_start
print('tflite_model_eval_time_elapsed:', tflite_model_eval2_time_elapsed)

def metrics(actual: np.array, predicted: np.array) -> np.array:
    # Confusion matrix elements
    TP = np.count_nonzero(predicted * actual)
    TN = np.count_nonzero((predicted - 1) * (actual - 1))
    FP = np.count_nonzero(predicted * (actual - 1))
    FN = np.count_nonzero((predicted - 1) * actual)

    # Classification evaluation metrics
    precision = TP / (TP + FP)
    recall = TP / (TP + FN)
    f1 = 2 * precision * recall / (precision + recall)
    accuracy = (TP + TN) / (TP + TN + FP + FN)

    return np.array([precision, recall, f1, accuracy])

_predictions = np.array(predictions)
_actual = edge_dataset['label_no'].values.astype('bool')
tflite_precision, tflite_recall, tflite_f1, tflite_accuracy2 = metrics(_actual, _predictions)
print('TFLite precision:', tflite_precision, 'recall:', tflite_recall, 'f1:', tflite_f1, 'accuracy:', tflite_accuracy2)

import seaborn as sns
from sklearn.metrics import confusion_matrix
sns.set(rc={'figure.figsize':(15,15)}, font_scale=2)

#Generate the confusion matrix
cf_matrix = confusion_matrix(_actual, _predictions)
print(cf_matrix)

ax = sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, cmap='YlGnBu', fmt='.2%')

ax.set_title('TFLite LSTM Classification Confusion Matrix\n');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['Normal','Abnormal'])
ax.yaxis.set_ticklabels(['Normal','Abnormal'])

plt.show()

timestamp = str(datetime.now())
stats = f'''Run stats (in sec) - {timestamp}
--------------------------TF---------------------------
training_time_elapsed: {training_time_elapsed}
eval_time_elapsed: {eval_time_elapsed} - accuracy: {accuracy}
model_export_time_elapsed: {model_export_time_elapsed}
---------------------------TFLite-----------------------
tflite_eval_time_elapsed (using model maker): {tflite_eval_time_elapsed} - accuracy: {tflite_accuracy}
tflite_model_eval2_time_elapsed (using interpreter): {tflite_model_eval2_time_elapsed} - accuracy: {tflite_accuracy2}
-------------------------------------------------------
No. of CPU cores: {multiprocessing.cpu_count()}
Hardware: {device_lib.list_local_devices()}
'''
print(stats)

# Save stats as a text file
with open('stats - ' + timestamp + '.csv', "a") as text_file:
    text_file.write(stats)

# csv file header: ['timestamp', 'training_time_elapsed', 'eval_time_elapsed', 'model_export_time_elapsed', 'tflite_eval_time_elapsed', 'tflite_model_eval2_time_elapsed', 'accuracy', 'tflite_accuracy', 'tflite_accuracy2', 'epochs'])
stats_list = [timestamp, training_time_elapsed, eval_time_elapsed, model_export_time_elapsed, tflite_eval_time_elapsed, tflite_model_eval2_time_elapsed, accuracy, tflite_accuracy, tflite_accuracy2, EPOCHS]
with open('../stats' + '.csv', "a") as csv_output_file:
    writer = csv.writer(csv_output_file)
    writer.writerow(stats_list)

# tflite csv file header: ['timestamp', 'tflite_eval_time_elapsed', 'tflite_model_eval2_time_elapsed', 'tflite_precision', 'tflite_recall', 'tflite_f1', 'tflite_accuracy'])
tflite_stats_list = [timestamp, tflite_eval_time_elapsed, tflite_model_eval2_time_elapsed, tflite_precision, tflite_recall, tflite_f1, tflite_accuracy2]
with open('../tflite_stats' + '.csv', "a") as csv_output_file:
    writer = csv.writer(csv_output_file)
    writer.writerow(tflite_stats_list)